<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE tmx SYSTEM "tmx11.dtd">
<tmx version="1.1">
  <header creationtool="OmegaT" o-tmf="OmegaT TMX" adminlang="EN-US" datatype="plaintext" creationtoolversion="OmegaT-3.6.0" segtype="sentence" srclang="EN-US"/>
  <body>
<!-- Default translations -->
    <tu>
      <tuv lang="EN-US">
        <seg>"Graph processing" is one of many areas of big data research that make you feel like we've gone backwards in time.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T070256Z" creationid="Zhan" creationdate="20160427T070256Z">
        <seg>在大数据研究的众多领域中，"图处理" 是其中一个让你感觉好像我们返回旧时光的方向。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>"We are at the beginning of exponential growth in digital intelligence." — Elon Musk, Tesla CEO</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T031429Z" creationid="Zhan" creationdate="20160504T024102Z">
        <seg>"我们正处在数字智能指数增长的开端"— — Elon Musk，特斯拉首席执行官</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>"[AI can] make every doctor as good as the best doctor in the world at diagnosing skin cancer." — Mark Zuckerberg, Facebook CEO</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T024037Z" creationid="Zhan" creationdate="20160504T024037Z">
        <seg>"[人工智能可以] 让每一位医生如同世界上最好的医师一样来诊断皮肤癌。" — Mark Zuckerberg, Facebook 首席执行官</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>## Goals for 2016</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T080547Z" creationid="Zhan" creationdate="20160427T080547Z">
        <seg>## 2016年目标</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>## Progress in graph processing</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T070123Z" creationid="Zhan" creationdate="20160427T070123Z">
        <seg>## 图形处理进展</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>### Graph problems not graph algorithms.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T072502Z" creationid="Zhan" creationdate="20160427T072502Z">
        <seg>### 图问题不同于图算法。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>### Synchronous vs asynchronous graph processing</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160505T160050Z" creationid="Zhan" creationdate="20160505T160050Z">
        <seg>### 同步与异步的图处理</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>### Think like a computer scientist not a vertex</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T075838Z" creationid="Zhan" creationdate="20160427T075838Z">
        <seg>### 像计算机科学家一样思考而非一个顶点</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>#### Community detection</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T080114Z" creationid="Zhan" creationdate="20160427T080114Z">
        <seg>#### 社区发现</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>#### Differential dataflow</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T080517Z" creationid="Zhan" creationdate="20160427T080517Z">
        <seg>#### 微分数据流</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>#### Graph coloring</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T075858Z" creationid="Zhan" creationdate="20160427T075858Z">
        <seg>#### 图的着色</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>#### Label propagation</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T080406Z" creationid="Zhan" creationdate="20160427T080406Z">
        <seg>#### 标签传播</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>* Creating new alphabets
* Computers that dream about what they have learned
* Algorithms that learn to generate their own music
* AIs that generate fake images of people
* Computers that draw pictures with different artistic styles</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T022024Z" creationid="Zhan" creationdate="20160504T021814Z">
        <seg>* 建立新的字母表
* 计算机用它们所学的内容做梦
* 用算法进行音乐创作
* 使用 AI 来合成虚拟图像
* 可以用不同艺术风格进行绘画的计算机</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>* Data analysis/data mining
* Data warehousing
* Online transaction processing
* Virtualized infrastructure
* Graph analytics
* VDI</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T014646Z" creationid="Zhan" creationdate="20160428T014624Z">
        <seg>* 数据分析/数据挖掘
* 数据仓储
* 联机事务处理
* 虚拟化基础设施
* 图分析
* VDI</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>**Recommendation 1**: Authors of graph processing systems should be obliged to evaluate their implementations against other algorithms for the same problems.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T075601Z" creationid="Zhan" creationdate="20160427T075601Z">
        <seg>** 建议 1 **: 图处理系统的作者们应该有义务将其系统与解决同样的问题的其他算法相比较。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>**Recommendation 2**: Authors of graph processing systems should be obliged to clearly distinguish the expressivity of their system from others.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160505T155810Z" creationid="Zhan" creationdate="20160505T155810Z">
        <seg>** 建议 2* *: 图处理系统的作者应该有义务清楚地将他们系统的表达性与别人区别开来。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>... a supervised learning technique that has been used in the closely related context of document classication, where it has been shown to have lower complexity and higher robustness than other learning methods.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T005252Z" creationid="Zhan" creationdate="20160427T005252Z">
        <seg>......一种监督的学习技术，被用于密切相关上下文的文档分类，并比其他的学习方法显示出较低的复杂度和更高的鲁棒性。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>A decade ago, RAID vendors were having the same discussion when they were talking about front-end bandwidth (server to cache) vs. back-end bandwidth (cache to disk).</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T080219Z" creationid="Zhan" creationdate="20160428T080219Z">
        <seg>十年前，RAID 供应商有过相同的讨论，关于前端带宽 （服务器到缓存） 与后端带宽 （缓存到磁盘）。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>A graph coloring is an assignment of colors (think small integers) to graph nodes so that no edge references two nodes of the same color.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T080033Z" creationid="Zhan" creationdate="20160427T080033Z">
        <seg>图的着色是给图节点上色（可理解为小整数），同时保证没有一条边连接相同颜色的两个节点。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Accelerated research</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T030301Z" creationid="Zhan" creationdate="20160504T030301Z">
        <seg>加快的研究</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Again, this is a not-unreasonable trade-off if your algorithmic needs match the narrower interface, but not very helpful if you need to do something else.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160505T155538Z" creationid="Zhan" creationdate="20160505T155538Z">
        <seg>又一次，如果你的算法需要匹配的窄的接口，这还算不上一个不合理的折中，可是若要做些别的事情，那就并不非常有用。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>All good, right?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T013812Z" creationid="Zhan" creationdate="20160322T104204Z">
        <seg>挺不错，是吧?</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>All graph processing systems can implement these algorithms, so in order to "have a fair comparison", a requirement of getting most papers published, you have to restrict your attention to this sort of problem.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T072017Z" creationid="Zhan" creationdate="20160427T072017Z">
        <seg>所有的图处理系统均可以实现这些算法，因此，为"有一个公平的比较"，作为多数论文发表的条件，你必须将注意力局限到这类问题。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>All of these connectivity options are limited by PCIe bandwidth, and though that might change in the future, the issues will be the same: How much bandwidth is needed between the host server(s) and the storage system(s).</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T080101Z" creationid="Zhan" creationdate="20160428T080101Z">
        <seg>所有这些连接选项都要受到 PCIe 带宽限制，虽然这在未来会有改变，问题仍将相同︰ 主机服务器和存储系统之间需要多少带宽。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>All of this adds up to complexity that is hard to imagine and that people have spent careers trying to model.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T084401Z" creationid="Zhan" creationdate="20160428T084401Z">
        <seg>所有这一切加起来构成难以想象的复杂性，足以让人们用整个职业生涯来分析。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Already on github, there are 700+ unique projects using TensorFlow.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T030555Z" creationid="Zhan" creationdate="20160504T030555Z">
        <seg>在 github 上，已经有 700+ 基于 TensorFlow 的独特项目。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Already, TensorFlow is the most "popular" machine learning software: on github it has 19,000+ likes and 6,500+ forks.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T015216Z" creationid="Zhan" creationdate="20160504T015216Z">
        <seg>TensorFlow 已经是最"流行"的机器学习软件 ︰ 在 github 上已有 19,000+ 赞、与 6,500+ 分支。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>An interesting question for the future from the paper is “... whether storage capacity growth will fall behind data-growth rates, meaning that the standard model of storing all data forever will no longer be sustainable because of a shortage of available storage resources.” The chances of that are, in my estimation, close to certain.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T095232Z" creationid="Zhan" creationdate="20160427T015753Z">
        <seg>这篇论文向未来提出一个有趣的问题 "... 存储容量增长是否将落后于数据增长率，这意味着，由于可用存储资源的短缺，这种永远存储所有数据的标准模型将不可持续。" 其可能性是，据我估计，近乎必然。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>And even now, there are new libraries coming online almost every week.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T015742Z" creationid="Zhan" creationdate="20160504T015742Z">
        <seg>即便是现在，仍然每周都有新面孔上线。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>And if you don't believe me, look at what the top executives of the world's most forward-thinking companies are saying:</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T023613Z" creationid="Zhan" creationdate="20160504T023516Z">
        <seg>如果你不相信我，看看世界上那些有着最前瞻思维的企业高管们都在说︰</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>And, of course, the simpler object storage interfaces of cloud vendors, who also remove most of the management overhead from corporate IT.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T004337Z" creationid="Zhan" creationdate="20160503T004337Z">
        <seg>并且，当然，云供应商所提供的简单对象存储接口，也为公司 IT 架构免除大多数管理开销。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Anecdotally, a great deal of Giraph (an open-source version of Pregel) vertex "programs" look more like state machines driven by decisions made by the computation's master node; the vertices do constitute a massively parallel data plane, but the program logic is still centralized.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160505T153620Z" creationid="Zhan" creationdate="20160505T153620Z">
        <seg>有趣的是，大量的 Giraph （Pregel-开源版） 顶点"程序"看起来更像由主计算节点决策驱动下的状态机，顶点确实构成一个大规模并行数据平面，但程序逻辑却仍然是集中化的。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Another painful aspect of development is that your code that runs on your development box often doesn't run on your production box because of GPU/CPU differences.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T025649Z" creationid="Zhan" creationdate="20160504T025649Z">
        <seg>另一个开发过程中的痛苦之处在于，在开发环境中可以运行的代码常常不能运行于生产环境，原因在于 GPU/CPU 上的差异。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Are these algorithms actually "representative graph problems", like the papers claim, and should we continue to improve the performance of these algorithms, assuming good general graph processing will come out of this work?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T071531Z" creationid="Zhan" creationdate="20160427T071531Z">
        <seg>这些算法是否确实如同这些论文所述 "代表图问题"，而且我们是否应该继续提高这些算法的性能，并认为一般性图处理可以由此改善？</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>As 2015 draws to a close, the research published at top venues still targets pretty much pagerank, connected components via label propagation, and breadth-first distance labeling.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T071017Z" creationid="Zhan" creationdate="20160427T071017Z">
        <seg>随着 2015 年临近尾声，发表在顶级会议上的研究仍然相当多的聚焦于 pagerank，基于标签传播的联通子图，和广度优先距离标签。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>As a fun exercise, perhaps you could write down what you think would constitute progress?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T073846Z" creationid="Zhan" creationdate="20160427T073846Z">
        <seg>作个有趣的作业，也许你可以写下那些你认为可以促成进步的内容？</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>As devices get faster and faster, channel performance must keep up.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T072729Z" creationid="Zhan" creationdate="20160428T072729Z">
        <seg>随着设备越来越快、通道性能必须跟上。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>As disk drives and solid state drives (SSDs) get faster and faster, I think it is time we stop and look at what really matters, namely, how much work gets done, not how fast a device is.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T020404Z" creationid="Zhan" creationdate="20160428T020404Z">
        <seg>随着磁盘驱动器和固态硬盘 (SSD) 越来越快，我认为现在是时候停下脚步审视一下什么才是真正重要的方面，换句话说，能完成多少工作，而非设备如何快。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>As systems get bigger and namespaces get flatter, this problem is going to get even worse.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T084446Z" creationid="Zhan" creationdate="20160428T084446Z">
        <seg>随着系统变得更大和命名空间变得更宽阔，这个问题将变得更糟。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>As the system watches human interaction with the data set, it learns what is important and tiers, protects and stores data according to user needs.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T004925Z" creationid="Zhan" creationdate="20160427T004556Z">
        <seg>随着系统观察人与数据集的交互，它学会如何判断重要性并根据用户需要来分层、保护和存储数据。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>As the training set got larger, the accuracy for the smaller classes improved, reaching nearly 100 percent accuracy at around 30 percent of the training data included.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T015006Z" creationid="Zhan" creationdate="20160427T015006Z">
        <seg>随着训练集变得更大，较小分类精度持续提高，在训练数据的 30%左右可以达到近 100%的准确率。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>At CIDR 2013, the [GRACE graph processing system](http://wenleix.github.io/paper/grace_cidr2013.pdf), no relation to [the other Grace graph processing system](https://www.usenix.org/system/files/conference/atc12/atc12-final182.pdf), presented a way to relax synchrony requirements in programs that otherwise look like bulk synchronous processors.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T080354Z" creationid="Zhan" creationdate="20160427T080354Z">
        <seg>在 CIDR 2013 上, [GRACE 图处理系统](http://wenleix.github.io/paper/grace_cidr2013.pdf), 与 [另外一个 Grace 图处理系统](https://www.usenix.org/system/files/conference/atc12/atc12-final182.pdf) 无关，提出一种方法来缓解同步需求，有别于成批同步处理模式 (bulk synchronous processors)。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Authors and reviewers should treat reduced expressivity as a serious concern, and expanded expressivity as a real contribution.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160505T155925Z" creationid="Zhan" creationdate="20160505T155925Z">
        <seg>作者和审阅者应将表达性削弱视为一个严重的问题，将表现性扩大作为真正的贡献。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Authors should go and check out the [GAP benchmark suite](https://github.com/sbeamer/gapbs), which targets simpler problems like those above, but provides optimized implementations using algorithms you probably haven't ever heard of.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T075815Z" creationid="Zhan" creationdate="20160427T075815Z">
        <seg>作者应该去查阅 [GAP benchmark suite] (https://github.com/sbeamer/gapbs)，其不仅以上面的那些简单问题为目标，更提供你可能还没听说过的优化算法。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Because the benchmark only requires the result, not a specific implementation, research and progress happened.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T075308Z" creationid="Zhan" creationdate="20160427T075308Z">
        <seg>由于这项基准测试只需要结果，不考察特定实现、研究乃至相应进展。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Because the file size is not known a priori by most applications and most file systems do not have a pre-allocation command, allocations between multiple files being open and written at the same time get interspersed with each other.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T083026Z" creationid="Zhan" creationdate="20160428T083026Z">
        <seg>因为对于大多数应用程序和文件系统而言，没有预分配命令，文件大小不可预知，多个文件同时打开写入数据将造成所分配空间相互交错。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Before TensorFlow</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T015639Z" creationid="Zhan" creationdate="20160504T015639Z">
        <seg>在 TensorFlow 之前</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Being a crap algorithm isn't the worst thing.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T073136Z" creationid="Zhan" creationdate="20160427T073136Z">
        <seg>作为一种没用算法还不是最糟糕的事情。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Better image recognition, better speech recognition, autonomous cars, beating GO masters, machines able to play and beat video games, and much much more.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T023401Z" creationid="Zhan" creationdate="20160504T023401Z">
        <seg>更好的图像识别，更准的语音识别，自动驾驶汽车，击败围棋大师，学习成为电子游戏高手，这样的例子还有许多。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Between file systems, volume managers and now object storage systems, how does data get allocated and laid out on the storage systems?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T081812Z" creationid="Zhan" creationdate="20160428T081812Z">
        <seg>文件系统、卷管理器以及现在还有对象存储系统，其间应如何分配数据，又怎样在存储系统中摆放？</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>But NVM is not a perfect replacement for DRAM, even ignoring latency.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T015404Z" creationid="Zhan" creationdate="20160323T015404Z">
        <seg>然而 NVM 并非 DRAM 的理想替换品，就算不考虑延迟。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>But Xpoint DIMMS are coming soon, and neither will give you anything close to 1,000x performance
boost.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T013511Z" creationid="Zhan" creationdate="20160322T090211Z">
        <seg>不过 Xpoint DIMMS 也快到来，而且没有哪个可以向你提供近 1,000 倍性能提升。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>But even with new tools, such as graph databases, making sense of massive amounts of raw data is getting harder every day.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T004721Z" creationid="Zhan" creationdate="20160427T003024Z">
        <seg>然而即便是用上新工具，比方说图数据库，去处海量原始数据的难度依然与日俱增。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>But getting back to my point: What matters is how much work you get done, not how fast your storage is, and faster storage does not always translate into more work getting done.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T084634Z" creationid="Zhan" creationdate="20160428T084634Z">
        <seg>不过现在返回出发点：真正重要的还是你能作多少事，而非存储如何快，更何况快速存储并不总是意味着能做更多事。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>But the huge mass of users will take lower costs over the last possible IOP.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T010313Z" creationid="Zhan" creationdate="20160503T010313Z">
        <seg>但海量的普通用户仍将在满足所需 IOP 时尽可能降低成本。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>But what are the implications of cheap IOPS for enterprise data center operations?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T002352Z" creationid="Zhan" creationdate="20160503T002352Z">
        <seg>但廉价 IOPS 于企业数据中心而言意味着什么？</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>By fixating only on the easiest of problems, researchers spiral into over-optimized and under-capable systems.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T072231Z" creationid="Zhan" creationdate="20160427T072231Z">
        <seg>由于仅聚焦于这类最简化问题，研究者们一直在过于优化与能力不足系统之间转圈。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>CFOs who don’t know a switch from server can read AWS prices and put the heat on CIOs.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T005756Z" creationid="Zhan" creationdate="20160503T005756Z">
        <seg>不知道服务器开关在何处的首席财务官可以读 AWS 报价然后把任务转给首席信息官。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Cloud is the vise crushing EDC costs.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T005547Z" creationid="Zhan" creationdate="20160503T005508Z">
        <seg>云是影响企业数据中心成本的第二大要素</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Cloud.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T005351Z" creationid="Zhan" creationdate="20160503T005351Z">
        <seg>云。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Commoditizing novel implementations of NVM – such as the hybrid memories this paper examines – will be a longer and more fraught process, but essential if we are to improve the efficiency and performance of all kinds of computer systems.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T022359Z" creationid="Zhan" creationdate="20160323T021942Z">
        <seg>将 NVM 的新颖实现商品化 – 比如说文中分析的混合存储 – 将会是一项长期且艰巨的任务，不过若我们希望改善各种计算机系统的效率与性能，那也非常关键。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Conclusion</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T020328Z" creationid="Zhan" creationdate="20160504T020328Z">
        <seg>结论</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Connectivity to Storage Systems
The options for connectivity to the storage systems today are SAS, Infiniband, Fibre Channel and NVMe.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T075706Z" creationid="Zhan" creationdate="20160428T075706Z">
        <seg>存储系统连接
现在用于连接存储系统的选项有 SAS、Infiniband、光纤通道和 NVMe。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Cost.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T004708Z" creationid="Zhan" creationdate="20160503T004708Z">
        <seg>成本。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Courteous comments welcome, of course.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T010835Z" creationid="Zhan" creationdate="20160323T022014Z">
        <seg>欢迎礼貌讨论，当然。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Deep learning models can enable everyone to make novel combinations of algorithms and data to create applications that were not possible before.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T031633Z" creationid="Zhan" creationdate="20160504T021458Z">
        <seg>深学习模型让每个人能够尝试将新的算法和数据进行组合来创建应用程序，这在以往是不可能的。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Device Connectivity</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T072715Z" creationid="Zhan" creationdate="20160428T072715Z">
        <seg>设备的连接</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Establishing human trust in machine intelligence is a major domain problem – see Will Smith’s character in I, Robot.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T020930Z" creationid="Zhan" creationdate="20160427T020930Z">
        <seg>建立人类对机器智能的信任是一个主要的领域问题 — — 看看在《我，机器人》里面威尔 · 史密斯的角色。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Even for disk drives, the SAS layout on the storage controller can have one SAS lane saturated by four disk drives.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T075053Z" creationid="Zhan" creationdate="20160428T075053Z">
        <seg>甚至对于磁盘驱动器而言，存储控制器上的 SAS 布局中，四个磁盘驱动器就足以让一个 SAS 通道饱和。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Every researcher and company uses their preferred library.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T015902Z" creationid="Zhan" creationdate="20160504T015902Z">
        <seg>每个研究员和公司有着他们首选的程序库。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Everyone is handling much larger data stores now, so automation is a necessity.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T005908Z" creationid="Zhan" creationdate="20160503T005908Z">
        <seg>所有人正在面对越来越大的数据存储，自动化已成必需。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Everyone, including YOU, has the opportunity to create new and wonderful machine learning applications now.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T022120Z" creationid="Zhan" creationdate="20160504T022120Z">
        <seg>任何人，包括你，已经拥有创造新颖且美妙的机器学习应用的契机。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Everything is a potential bottleneck along the data path — from the number of applications to the file system (and let’s not forget the operating system!) to the PCIe bus to the channel all the way to the device.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T084255Z" creationid="Zhan" creationdate="20160428T084255Z">
        <seg>在数据路径上任何一处都是一个潜在的瓶颈 — — 从文件系统中应用的数量 （我们别忘记操作系统 ！） 到 PCIe 总线到通往设备的通道。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Except each storage medium has its issues and NVM is no exception.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T013817Z" creationid="Zhan" creationdate="20160322T104247Z">
        <seg>只不过每一种存储媒介都有它的问题，NVM 也不例外。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Existing file systems built for spinning or solid-state disks introduce software overheads that would obscure the performance that NVMs should provide, but proposed file systems for NVMs either incur similar overheads or fail to provide the strong consistency guarantees that applications require.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T013837Z" creationid="Zhan" creationdate="20160322T104805Z">
        <seg>现有用于旋转磁盘或固态盘的文件系统所带来的软件开销将会削弱 NVM 原本应该提供的性能，然而现在为 NVM 设计的文件系统要么也有相似的开销，要么无法提供应用需要的强一致性保证。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Experimental results</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T004934Z" creationid="Zhan" creationdate="20160427T004934Z">
        <seg>实验结果</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Experimental results show that in write-intensive workloads, NOVA provides 22% to 216× throughput improvement compared to state-of-the-art file systems, and 3.1× to 13.5× improvement compared to file systems that provide equally strong data consistency guarantees.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T014523Z" creationid="Zhan" creationdate="20160323T014523Z">
        <seg>实验结果展示出就写密集负载而言，NOVA 可以提供比现有文件系统高出 22% 直至 216 倍的性能提升，而且即便与提供相同强一致性保障的文件系统相比，性能也有 3.1 倍到 13.5 倍的提升。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Fallibility will always be part of an AI’s nature.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T044850Z" creationid="Zhan" creationdate="20160427T044850Z">
        <seg>易错性总会是人工智能本质的一部分。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Faster storage requires re-engineering the back-end storage system to ensure that there is enough bandwidth so each storage device can run at full rate.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T075138Z" creationid="Zhan" creationdate="20160428T075138Z">
        <seg>更快的存储需要重新设计的后端存储系统以确保提供足够的带宽，使每个存储设备可以全速运转。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Feel free to contact us.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T020655Z" creationid="Zhan" creationdate="20160504T020655Z">
        <seg>欢迎与我们联系。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>First things
Is data center storage getting simpler?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T002512Z" creationid="Zhan" creationdate="20160503T002458Z">
        <seg>第一件事
数据中心存储正变得更简单？</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Flash makes high performance a given.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T005348Z" creationid="Zhan" creationdate="20160503T005348Z">
        <seg>闪存直接就能提供高性能。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Flash.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T004849Z" creationid="Zhan" creationdate="20160503T004849Z">
        <seg>闪存。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>For IBM, a world leader in AI, as their success with Watson has demonstrated, applying intelligence to the problem of storage is a natural application.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T004653Z" creationid="Zhan" creationdate="20160427T003649Z">
        <seg>就 IBM 而言，作为人工智能 (AI) 的领导者，基于在 Watson 上所展现出来的成功，将智能性应用在存储问题上是自然之选。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>For an alternate approach, consider the [graph500 benchmark](http://www.graph500.org), originally conceived as a way to evaluate memory subsystems.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T074344Z" creationid="Zhan" creationdate="20160427T074344Z">
        <seg>作为另一种方法，请考虑 [graph500 基准] (http://www.graph500.org)，最初被视为一种内存子系统评价方法。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>For an interesting overview of the Gödel Machine, deep learning, and how a program can rewrite itself while running, Schmidhuber’s lecture is an excellent introduction.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T044527Z" creationid="Zhan" creationdate="20160427T044527Z">
        <seg>Schmidhuber 的讲座为哥德尔机、深度学习，以及程序如何在运行时重写自身提供了一个不错的有趣介绍。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>For each new paper that is published in machine learning, it is usually followed by several open source implementations each written in a different framework and only meant to run on a specific hardware.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T020147Z" creationid="Zhan" creationdate="20160504T020147Z">
        <seg>在每一篇发表于机器学习领域的新论文中，总包含着几个开放源码实现，各自用不同的框架所写，只运行于特定的硬件上。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>For example, [PowerGraph](https://www.usenix.org/system/files/conference/osdi12/osdi12-final-167.pdf) introduced the Gather, Apply, Scatter (GAS) interface, which allows one to program input combiners, vertex logic, and disemination.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160505T154350Z" creationid="Zhan" creationdate="20160505T154350Z">
        <seg>例如，[PowerGraph] (https://www.usenix.org/system/files/conference/osdi12/osdi12-final-167.pdf) 介绍了 Gather, Apply, Scatter (GAS) 接口，允许用户就输入组合生成器、 顶点逻辑和传播方式编程。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>For example, if you have a standard POSIX file system, the file system’s allocation policy is first in first out (FIFO).</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T081836Z" creationid="Zhan" creationdate="20160428T081836Z">
        <seg>例如，如果你有一个标准的 POSIX 文件系统，文件系统的空间分配策略是先入先出 (FIFO)。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>For those coming in late, the upcoming NVM technologies, of which Xpoint is only one, promise faster writes, higher endurance, and greater longevity than the NAND flash used in today’s SSDs.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T013747Z" creationid="Zhan" creationdate="20160322T090801Z">
        <seg>如果原来不是很清楚，发展中的 NVM 技术里，Xpoint 只是其中之一，具备更快的写操作，更高的耐久性，以及比现在固态盘中使用的 NAND flash 更高的使用寿命。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>From Jian’s abstract:
... managing, accessing, and maintaining consistency for data stored in NVM raises a host of challenges.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T013827Z" creationid="Zhan" creationdate="20160322T104359Z">
        <seg>在 Jian 的摘要中:
... 管理，访问，和维护保存在 NVM 中数据的一致性引出不少挑战。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>From the abstract of the paper A Family of Gödel Machine Implementations by Bas R. Steunebrink and Jürgen Schmidhuber of the IDSIA &amp; University of Lugano:</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T042408Z" creationid="Zhan" creationdate="20160427T042408Z">
        <seg>这篇论文《一类哥德尔机的实现》(A Family of Gödel Machine Implementations) 由来分别来自于 IDSIA 和 Lugano 大学的 Bas R. Steunebrink 和 Jürgen Schmidhuber 完成，其摘要里说：</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Goodbye, old bottleneck</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T001946Z" creationid="Zhan" creationdate="20160503T001946Z">
        <seg>再见了，老的瓶颈</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Google is also relentlessly releasing updates, supporting products, and training courses.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T015246Z" creationid="Zhan" creationdate="20160504T015246Z">
        <seg>谷歌还在持续地发布更新，提供产品支持和培训课程。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Graph processing systems have introduced progressively more restrictive APIs in the name of performance, creating a race to the bottom with respect to expressivity.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160502T064031Z" creationid="Zhan" creationdate="20160502T064031Z">
        <seg>图处理系统已经以性能的名义逐步引进更严格的 APIs，造成一场追逐表达性的竞争。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Gödel Machines, deep learning and the limits of AI
by ROBIN HARRIS on WEDNESDAY, 13 JANUARY, 2016
If, like me, you’re interested in AI and deep learning, you’ll like this.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T094657Z" creationid="Zhan" creationdate="20160427T031213Z">
        <seg>哥德尔机器、深度学习和人工智能的极限
罗宾 · 哈里斯 星期三 2016 年 1 月 13 日
如果像我一样，你对人工智能(AI)和深度学习(Deep Learning)有兴趣，你会喜欢这贴。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Gödel machines run on von Neumann architectures – they are not a new computer architecture.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T043231Z" creationid="Zhan" creationdate="20160427T043231Z">
        <seg>哥德尔机可以在冯 · 诺依曼体系结构上运行 — — 他们不是一个新的计算机体系结构。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Here are my thoughts on why the area isn't making very much progress, and is in some cases regressing, as well as a few proposals for making thing better.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T070834Z" creationid="Zhan" creationdate="20160427T070834Z">
        <seg>这里我谈一些我的想法，为什么这个区域没有实现什么进展，并且在某些情况下还有所退步，以及提几个改进建议。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Host Side</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T080746Z" creationid="Zhan" creationdate="20160428T080746Z">
        <seg>主机端</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>How AI will change everything</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T031454Z" creationid="Zhan" creationdate="20160504T020843Z">
        <seg>AI 将如何改变一切</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>However, in my mind the most interesting thing to happen with graph500 was [Scott Beamer](http://www.cs.berkeley.edu/~sbeamer/research.html) and friends observing that a tweaked algorithm could traverse fewer edges, accomplishing the same result but moving less data over the memory subsystem.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T075206Z" creationid="Zhan" creationdate="20160427T075206Z">
        <seg>然而，在我的印象中发生在 graph500 上最有趣的事情莫过于 [Scott Beamer] (http://www.cs.berkeley.edu/~sbeamer/research.html)，据朋友们观察，一项调整的算法可以通过遍历更少的边以实现相同的结果，从而在内存子系统移动较少的数据。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>However, the fixation on known problems (pagerank, connectivity, etc) leads us towards more and more restrictive programming models.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160505T153938Z" creationid="Zhan" creationdate="20160505T153938Z">
        <seg>然而，执着于已知问题 （pagerank、 连通性等） 又将方向引至受更多限制的编程模型。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>I do not think the main problem with graph processing systems is that they do not yet compute PageRank fast enough; I think the problem is that they mostly just compute PageRank.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160505T155648Z" creationid="Zhan" creationdate="20160505T155648Z">
        <seg>我不认为图处理系统的主要问题是，他们计算 PageRank 还不够快，我觉得问题是，他们大多只计算 PageRank。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>I n October 2015, Google released a piece of machine learning software called TensorFlow.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T012211Z" creationid="Zhan" creationdate="20160504T012211Z">
        <seg>2015 年 10 月，Google 发布了一款名为 TensorFlow 的机器学习软件。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>I've spoken with dozens of research labs over the past few months and most are already moving to TensorFlow or exploring moving to it.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T030420Z" creationid="Zhan" creationdate="20160504T030420Z">
        <seg>在过去的几个月里我与不少研究实验室交流过，大部分都已经将自己的工作迁移上 TensorFlow 或正在尝试使用它。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>IB, essentially, relates the information’s metadata values to cognitive system relevance values with the goal of preserving the mutual information between the two.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T005545Z" creationid="Zhan" creationdate="20160427T005545Z">
        <seg>IB，本质上，为信息的元数据价值，与认知系统相关值建立关联，目的是保持两者之间的互信息。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>IBM researchers are proposing – and demoing – an intelligent storage system that works something like your brain.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T002120Z" creationid="Zhan" creationdate="20160427T002120Z">
        <seg>IBM 提出 – 和展示 – 一款可以如大脑一般运作的智能存储系统.</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>IBM’s Watson runs on a massively parallel system, and I assume a Gödel Machine can too.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T045713Z" creationid="Zhan" creationdate="20160427T044750Z">
        <seg>IBM 的沃森(Watson)运行在大规模并行系统上，我认为哥德尔机也可以。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>If in one case you have a single application writing say 500 GB in 1 MB chunks sequentially, and if you have enough free space, the file will be allocated with sequential block addresses in the file system.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T082047Z" creationid="Zhan" creationdate="20160428T082047Z">
        <seg>如果在一个案例中你有一个应用程序按照 1 MB 块大小顺序写 500 GB 1 MB 数据，而且如果你有足够的可用空间，该文件将在文件系统中被分配连续块地址。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>If two applications are writing two different 500 GB files, then it is almost certain that the files will not be sequentially allocated on a disk, given that file systems allocate data based on their allocation policy, which could pre-allocate ahead but certainly not 500 GB.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T082705Z" creationid="Zhan" creationdate="20160428T082705Z">
        <seg>如果两个应用程序分别写两个不同的 500 GB 文件，那么就几乎可以肯定不会在磁盘上按顺序分配，考虑到文件系统是按照其分配策略分配数据，有可能预先分配空间，不过肯定没有 500 GB。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>If you are at all interested in machine learning, I suggest you start hacking on top of TensorFlow.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T020645Z" creationid="Zhan" creationdate="20160504T020645Z">
        <seg>若你对机器学习有兴趣，我建议你从 TensorFlow 开始。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>If you want to better understand what the latest research and techniques that are being used to understand workflows and how that impacts system performance and systems architecture, I suggest you pack your bags and head to Santa Clara for MSST.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T085942Z" creationid="Zhan" creationdate="20160428T085942Z">
        <seg>如果你想要更好地理解最新的研究工作和那些正被用来认识工作流及其如何影响系统性能和系统体系结构的技术，我建议你收拾行囊去圣塔克拉拉参加 MSST。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>If your storage systems are due a refresh and you are planning future purchases, then there's a huge elephant in the room that needs addressing: Intel and Micron's high performance 3D XPoint technology.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T014236Z" creationid="Zhan" creationdate="20160428T014236Z">
        <seg>如果你的存储系统需要更新而且你正在计划未来的采购，那现在这里就有一个重磅消息值得关注︰ 英特尔和镁光的高性能 3D XPoint 技术。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>If you’re processing IoT data sets, the storage system’s AI would have processed what is important about prior data sets and apply those criteria – access frequency, protection level, divergence from norms, time value, – to the incoming data.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T004622Z" creationid="Zhan" creationdate="20160427T004126Z">
        <seg>如果您正在处理物联网数据集, 存储系统 AI 将在处理之前的数据集时分析出其重要性并且将有关特性 — — 访问频率、保护级别、偏离度、时间价值 — — 应用于未来的数据。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Imagination and experimentation are the fuel that will create intelligence that we have never seen before.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T021650Z" creationid="Zhan" creationdate="20160504T021650Z">
        <seg>想象力和实验将为开展前所未见的智能创作提供燃料。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>In Cognitive Storage for Big Data (paywall), IBM researchers Giovanni Cherubini, Jens Jelitto, and Vinodh Venkatesan, of IBM Research—Zurich, described their prototype system.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T004638Z" creationid="Zhan" creationdate="20160427T004046Z">
        <seg>在《认知存储大数据》 （付费）上，来自 IBM 苏黎世研究所的研究人员 Giovanni Cherubini, Jens Jelitto 和 Vinodh Venkatesan，描述了其原型系统。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>In a recent paper, NOVA: A Log-structured File System for Hybrid Volatile/Non-volatile Main Memories Jian Xu and Steven Swanson of the University of California, San Diego, discuss NVM integration issues.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T013719Z" creationid="Zhan" creationdate="20160322T090321Z">
        <seg>在最近一篇论文，NOVA: A Log-structured File System for Hybrid Volatile/Non-volatile Main Memories 中，来自加州大学圣迭戈分校的 Jian Xu 与 Steven Swanson 探讨了 NVM 集成问题。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>In particular, it maintains separate logs for each inode to improve concurrency, and stores file data outside the log to minimize log size and reduce garbage collection costs.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T014214Z" creationid="Zhan" creationdate="20160323T014214Z">
        <seg>特别的，它还为每一个 inode 分别维护日志以提高并行性，而且将文件数据保存在日志之外来最小化日志尺寸，减少垃圾回收代价。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Integrating 3D Xpoint with DRAM
by Robin Harris on Monday, 21 March, 2016
Intel is promising availability of 3D Xpoint non-volatile memory (NVM) this year, at least in their Optane
SSDs.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160322T085000Z" creationid="Zhan" creationdate="20160322T085000Z">
        <seg>将 3D Xpoint 与 DRAM 整合
作者 Robin Harris 于 星期一, 2016 年 3 月 21 日
Intel 承诺将于今年发售 3D Xpoint 非易失存储器 (NVM), 至少在他们的 Optane
固态盘中.</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Integrating 3D Xpoint with DRAM
by Robin Harris on Monday, 21 March, 2016
Intel is promising availability of 3D Xpoint non-volatile memory (NVM) this year, at least in their Optane SSDs.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T051507Z" creationid="Zhan" creationdate="20160322T090032Z">
        <seg>将 3D Xpoint 与 DRAM 整合
作者 Robin Harris 于 星期一，2016 年 3 月 21 日
Intel 承诺将于今年发售 3D Xpoint 非易失存储器 (NVM)，至少在他们的 Optane 固态盘中。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Is it hype?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T022656Z" creationid="Zhan" creationdate="20160504T022656Z">
        <seg>它是炒作吗？</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Is the storage admin an endangered species?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T012206Z" creationid="Zhan" creationdate="20160503T010659Z">
        <seg>存储管理员就要成濒危物种啰？</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Is this going to work at enterprise scale or will it be a purely web-scale service?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T022537Z" creationid="Zhan" creationdate="20160427T022537Z">
        <seg>是否在在企业规模适用或它将成为一个纯粹的互联网尺寸服务？</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>It is a cute idea that has some cachet, and appears to make the complexity of graph processing a bit more manageable.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160502T065214Z" creationid="Zhan" creationdate="20160502T065214Z">
        <seg>它是一个可爱的想法，有较好的口碑，而且似乎使图形处理的复杂性有点更易于管理。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>It is great that there is all this experimentation with different interfaces, but there needs to be consolidation if we want to move faster.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T030257Z" creationid="Zhan" creationdate="20160504T030257Z">
        <seg>为不同的接口都开展实验，那是很不错，但如果我们想要运行的更快，还需要整合。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>It is harder to evaluate expressivity than raw performance, but it is absolutely the most interesting research direction at the moment.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160505T160026Z" creationid="Zhan" creationdate="20160505T160026Z">
        <seg>比起纯粹性能而言更难评价表现性，但它绝对是目前最有趣的研究方向。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>It is the second-generation software for machine learning infrastructure built at Google, and it powers many of their products such as Google Inbox, Google Translator, Youtube, Google Ads, and more.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T015055Z" creationid="Zhan" creationdate="20160504T015055Z">
        <seg>这是 Google 开发的第二款用于机器学习的基础架构软件，而且已经被用于诸如 Google 收件箱，Google 翻译，Youtube，Google 广告等产品。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>It made a lot of sense for the authors, because they could compute what they needed and be done with it.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T073558Z" creationid="Zhan" creationdate="20160427T073558Z">
        <seg>就作者而言这还是挺有意义，因为他们可以完成他们需要的计算。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>It seems that most graph processing systems are looking for similar sorts of interfaces that make graph processing easy, and high performance possible.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160505T153733Z" creationid="Zhan" creationdate="20160505T153733Z">
        <seg>似乎大多数的图处理系统正在寻找一种相似的使图处理易用，且高性能的接口。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>It's less helpful if you still need to do one of those tasks of Semih's up above.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160505T154815Z" creationid="Zhan" creationdate="20160505T154815Z">
        <seg>如果你仍需要执行上述 Semih 那些处理任务之一，这个方案就不太有用。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>It’s based on the idea that it’s easier to remember important, like a sunset over the Grand Canyon, than the last time you waited for a traffic light.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T004745Z" creationid="Zhan" creationdate="20160427T002338Z">
        <seg>其基于这样一个想法，就是越重要的事情越容易记住，比方说在大峡谷上的日落，之于上一次等红灯。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>It’s clear that the big iron arrays are sucking wind – EMC’s VMAX/VNX (Information Storage) group saw peak sales in Q4, 2014 – and I forecast that declining trend will accelerate in coming quarters and last for years.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T012146Z" creationid="Zhan" creationdate="20160503T002730Z">
        <seg>毫无疑问大块头阵列正处于风口浪尖 — — EMC 的 VMAX/VNX （信息存储） 团队在2014 年第 4 季度达至销售高峰 — — 我预测其下降趋势在未来几个季度将加快并持续多年。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>It’s like driving down the highway in second gear, there is potential to move a lot faster!!!</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T030035Z" creationid="Zhan" creationdate="20160504T030035Z">
        <seg>这就像在高速公路上用二档开车，原本有着跑得更快的潜力!!!</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>It’s possible that this could be another hype round, but I don't think so.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T022947Z" creationid="Zhan" creationdate="20160504T022947Z">
        <seg>这可能是另一个回合炒作，但我不这么认为。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>I’m also pleased – probably unjustifiably – by the notion that however smart Ais become, they won’t be perfect.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T045823Z" creationid="Zhan" creationdate="20160427T045108Z">
        <seg>这观点让我开心 – 虽然有些不太合适 – 无论人工智能将变得如何聪明，其仍无法完美。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>I’m curious about the system architecture running the Gödel Machine and the I/O workload the machine generates.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T044728Z" creationid="Zhan" creationdate="20160427T044728Z">
        <seg>我很好奇哥德尔机运行的系统体系结构及其生成的 I/O 工作负载。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Just as any software problem can be solved by adding a layer of indirection, any analytics problem can be solved by adding a layer of intelligence.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T004711Z" creationid="Zhan" creationdate="20160427T003350Z">
        <seg>如同任何软件问题都可以通过增加一个间接层来解决一样，任何一项分析问题也可以通过补充一个智能层来处理。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Just look at some of the amazing ideas people have built recently:</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T021725Z" creationid="Zhan" creationdate="20160504T021725Z">
        <seg>来看一些人们最近建立起的惊人想法︰</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Just understanding what system calls are made from all of the applications from strace tells you only part of the story, as it does not provide an understanding of what is happening on the storage level.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T085316Z" creationid="Zhan" creationdate="20160428T085316Z">
        <seg>用 strace 来了解应用程序执行着哪些系统调用只不过是故事的一部分，因为这不能让人理解在存储层面上发生着什么。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Let's be clear, all the research to be published in 2016 has already been done and written by this point.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T080727Z" creationid="Zhan" creationdate="20160427T080727Z">
        <seg>我们应该清楚，所有要在 2016 年发表的研究成果必须已经完成，而且已经写好。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Let's talk about that now.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T080444Z" creationid="Zhan" creationdate="20160427T080444Z">
        <seg>我们现在谈谈这个问题。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Let’s start at the device and work our way up the stack.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T021040Z" creationid="Zhan" creationdate="20160428T021040Z">
        <seg>让我们从设备一侧开始，工作我们沿着堆栈向上进行分析。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Looking for a version that runs on your mac?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T020213Z" creationid="Zhan" creationdate="20160504T020213Z">
        <seg>想找个可以在你的 mac 电脑上运行的版本吗？</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Modern CPU and memory systems may reorder stores to memory to improve performance, breaking consistency in case of system failure.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T015808Z" creationid="Zhan" creationdate="20160323T015808Z">
        <seg>当代 CPU 与主存系统常将重组数据存储于主存以改善性能，系统出现故障时一致性将被破坏。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>More importantly, I expect that several NVM types will be coming to market over the next 5 years.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T020522Z" creationid="Zhan" creationdate="20160323T020522Z">
        <seg>更为重要的是，我期待着在未来5年里有几种类型的 NVM 能够进入市场。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Most controllers were designed with significantly more front-end bandwidth with the assumption that much of the data accessed would reside in cache.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T080353Z" creationid="Zhan" creationdate="20160428T080353Z">
        <seg>大多数的控制器在设计上给前端带宽很大的余量，这是基于大部分数据访问将集中在缓存中的假设。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>NOVA adapts conventional log-structured file system techniques to exploit the fast random access that NVMs provide.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T014031Z" creationid="Zhan" creationdate="20160323T014031Z">
        <seg>NOVA 采用常规的日志文件系统技术，以发挥 NVM 提供的高速随机访问优势。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Neural networks are all the rage in AI, but there is a newer technology – Gödel machines – that is now a standard part of the AI toolset.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T041730Z" creationid="Zhan" creationdate="20160427T041730Z">
        <seg>神经网络在人工智能领域正广受关注，然而还有新技术 — — 哥德尔机 — — 现在也成为 AI 工具集的一个标准部分。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>No.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T071539Z" creationid="Zhan" creationdate="20160427T071539Z">
        <seg>不。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Nonetheless, the IBM team is doing important work.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T023209Z" creationid="Zhan" creationdate="20160427T023209Z">
        <seg>然而，IBM 团队正做着做重要的工作。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Now we get to the hard part of the equation.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T080820Z" creationid="Zhan" creationdate="20160428T080820Z">
        <seg>现在我们来到这个问题中困难的部分。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Of course this is not only true for storage but also true for the computational side, as faster CPUs and more cores do not always translate into more work.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T084814Z" creationid="Zhan" creationdate="20160428T084814Z">
        <seg>当然不仅对于存储如此，计算方面也一样，速度更快的 CPU 和更多内核不总是会转化为完成更多的工作。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Of course, we know a lot more about indirection than we do intelligence.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T004703Z" creationid="Zhan" creationdate="20160427T003456Z">
        <seg>无疑，相比于智能，我们更理解间接。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Often times you would need to rebuild or convert your model to work on different architectures.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T025801Z" creationid="Zhan" creationdate="20160504T025801Z">
        <seg>而且重制或者转换模型以运行于不同系统结构这种情况也挺常有。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>On top of that, we will see many new platforms made specifically for TensorFlow.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T020559Z" creationid="Zhan" creationdate="20160504T020559Z">
        <seg>以此为基础，我们将会看到更多用 TensorFlow 创作的新平台。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Or how about a version that runs on your cell phone, it might not exist.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T020315Z" creationid="Zhan" creationdate="20160504T020315Z">
        <seg>或一款可在你的手机上运行的版本，它可能不存在。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>People are ≈70% of enterprise data center cost.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T005514Z" creationid="Zhan" creationdate="20160503T004809Z">
        <seg>人力资源 ≈70% 企业数据中心开销。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Photo courtesy of Shutterstock.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T080849Z" creationid="Zhan" creationdate="20160428T080849Z">
        <seg>照片由 Shutterstock 提供。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Placing a much-faster-than-flash-but-slower-and-cheaper-than-DRAM NVM on the processor's memory bus makes perfect sense.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T015251Z" creationid="Zhan" creationdate="20160323T015251Z">
        <seg>将显著快过闪存且稍慢、稍便宜于 DRAM 的 NVM 放置在处理器的主存总线上更有意义。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Platforms</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T030805Z" creationid="Zhan" creationdate="20160504T030805Z">
        <seg>平台</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Posted April 21, 2016
By Paul Rubens
http://www.enterprisestorageforum.com/storage-technology/does-3d-xpoint-spell-the-end-for-flash-storage-1.html</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T014035Z" creationid="Zhan" creationdate="20160428T014035Z">
        <seg>发布 2016 年 4 月 21 日
由 Paul Rubens
http://www.enterprisestorageforum.com/storage-technology/does-3d-xpoint-spell-the-end-for-flash-storage-1.html</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Posted March 17, 2016
By Henry Newman
http://www.enterprisestorageforum.com/storage-hardware/why-workloads-matter-more-than-iops-or-streaming.html</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T020126Z" creationid="Zhan" creationdate="20160428T020126Z">
        <seg>发布于 2016 年 3 月 17 日
由亨利 · 纽曼
http://www.enterprisestorageforum.com/storage-hardware/why-workloads-matter-more-than-iops-or-streaming.html</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Presumably the original assumption was that folks would use breadth-first graph traversal, which exercised the memory subsystem in the way the benchmark authors intended (a mix of bulk memory access and pointer chasing).</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T074831Z" creationid="Zhan" creationdate="20160427T074831Z">
        <seg>是初的假设大概是，人们会使用广度优先遍历图，由此内存子系统访问将按照基准测试作者的意图 （大块内存访问和指针追逐的混合） 的方式进行。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Providing strong consistency guarantees is particularly challenging for memory-based file systems because maintaining data consistency in NVMM can be costly.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T015554Z" creationid="Zhan" creationdate="20160323T015554Z">
        <seg>提供强一致性保证就基于内存的文件系统而言颇具挑战性，因为在 NVMM 中维护数据一致性代价不菲。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Rather, they are representative of algorithms that can be expressed in the lowest-common-denominator systems.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T071731Z" creationid="Zhan" creationdate="20160427T071731Z">
        <seg>相反，他们是代表着最低共性特征的算法。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Remember label propagation for connected components?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T080426Z" creationid="Zhan" creationdate="20160427T080426Z">
        <seg>还记得联通子图所用的标签传播吗？</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Research in machine learning has had all these roadblocks that create fragmentation and slow down progress.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T025931Z" creationid="Zhan" creationdate="20160504T025931Z">
        <seg>在机器学习的研究之中，有着这许多路障，使得过程碎片化并因此减缓。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Scale.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T005808Z" creationid="Zhan" creationdate="20160503T005808Z">
        <seg>扩展。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Searcher.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T043457Z" creationid="Zhan" creationdate="20160427T043457Z">
        <seg>搜索者。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Semih Salihoglu and Jennifer Widom have [a paper in VLDB](http://ilpubs.stanford.edu:8090/1077/3/p535-salihoglu.pdf) detailing what they had to do to get non-trivial graph algorithms working well in a Pregel-like system.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160505T153214Z" creationid="Zhan" creationdate="20160505T153214Z">
        <seg>Semih Salihoglu 和 Jennifer Widom 发飙了 [一篇 VLDB 论文](http://ilpubs.stanford.edu:8090/1077/3/p535-salihoglu.pdf) 详细介绍了他们如何使非简易图算法在 Pregel 类型系统中良好运行。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Simpler storage = fewer and cheaper people.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T004843Z" creationid="Zhan" creationdate="20160503T004843Z">
        <seg>简单存储 = 更少的人手需求，更低的人力资源成本</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>So enabling machine intelligence to trash data is probably the most essential issue and value of cognitive storage – and the capability most likely to frighten users.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T020458Z" creationid="Zhan" creationdate="20160427T020458Z">
        <seg>启用机器智能来舍弃数据可能是认知存储最基本的问题和价值所在 — — 也是最有可能让用户害怕的能力。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>So just knowing what your application does is not everything; you need to try and understand what the storage system is doing with your application and you also need to know what else is running on the system at the same time, which is a far more complicated task.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T083350Z" creationid="Zhan" creationdate="20160428T083350Z">
        <seg>所以只知道你的应用程序做了什么还不够; 你需要试着去了解与你的应用程序相应的存储系统做了什么，甚至还需要知道与此同时在系统上还运行着别的什么，这项任务更为复杂。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>So many papers confuse graph "problems" and graph "algorithms".</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T072523Z" creationid="Zhan" creationdate="20160427T072523Z">
        <seg>很多论文混淆图"问题"和图"算法"。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>So what does impact workload throughput for storage systems?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T020950Z" creationid="Zhan" creationdate="20160428T020950Z">
        <seg>所以是什么在影响存储系统的工作负载吞吐量？</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Solver.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T045551Z" creationid="Zhan" creationdate="20160427T043247Z">
        <seg>求解器。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Some are forecasting that we’ll be generating more data than we’ll have capacity to store once IoT gets rolling.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T002652Z" creationid="Zhan" creationdate="20160427T002652Z">
        <seg>已有预测指出，一旦物联网广泛运用，我们产生的数据将超过我们所拥有的存储容量.</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Some well-known ones:</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T015803Z" creationid="Zhan" creationdate="20160504T015803Z">
        <seg>这些比较有名：</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Sounds workable!</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T015025Z" creationid="Zhan" creationdate="20160427T015025Z">
        <seg>听起来可行！</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Storage costs continue to fall faster than computational costs, creating a difficult economic dynamic for cognitive storage.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T023144Z" creationid="Zhan" creationdate="20160427T023144Z">
        <seg>相比计算成本，存储成本持续下降更快，也因此给认知存储造成一种困难的经济环境。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>StorageMojo has often asked buyers to focus on latency rather than IOPS thanks to SSDs making IOPS cheap and plentiful.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T002137Z" creationid="Zhan" creationdate="20160503T002137Z">
        <seg>感谢固态盘让 IOPS 既便宜又充裕，StorageMojo 经常提醒购买者关注延迟而非 IOPS。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Sure, you can schlep unlikely-to-be-needed data off to low cost tape – IBM is a leading tape drive vendor – but the “store everything forever” algorithm doesn’t scale – and if something won’t scale forever, it won’t.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T021502Z" creationid="Zhan" creationdate="20160427T021502Z">
        <seg>当然，你能将不太可能被用到的数据转移进低成本磁带上— — IBM 是领先的磁带驱动器供应商 — — 但"永远存储一切"算法无法扩展 — — 只要有什么不能持续扩展，那就不会。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>TensorFlow is open source software for creating machine learning models, especially deep neural networks.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T014109Z" creationid="Zhan" creationdate="20160504T014109Z">
        <seg>TensorFlow 是一款开放源码软件，用于创建机器学习模型，尤其深度神经网络。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>That is amazing, consider it has only been out a few months!</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T030618Z" creationid="Zhan" creationdate="20160504T030618Z">
        <seg>那很惊人，要知道这才过了几个月 ！</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>That is my view of the main issue with graph processing research at the moment, but it shows up a few different ways.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T072442Z" creationid="Zhan" creationdate="20160427T072442Z">
        <seg>这是我认为此刻在图处理研究中存在的主要问题，也揭示出一些不同的途径。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>That, in a nutshell, is why systems won’t be able to advantage of NVM technology until their DRAM and disk I/O stacks are re-engineered for the specific advantages and quirks of NVM. The paper offers a smart way to adapt existing techniques to the brave new world of NVM.
From the paper:
...</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T013857Z" creationid="Zhan" creationdate="20160322T105518Z">
        <seg>那么，归纳起来，这也就是为什么除非将 DRAM 与磁盘 I/O 栈针对 NVM 的特殊优势与问题进行重新设计，系统将不可能发挥出 NVM 技术的先进性。这篇论文提供了一种聪明的方法来将现有技术适配到 NVM 的全新领域中。
文中还提到:
...</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>That’s what’s motivating the secular trend for simpler storage.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T002453Z" creationid="Zhan" creationdate="20160503T002453Z">
        <seg>这就是简单存储这个长期趋势的幕后推手。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>That’s why data scientists are in high demand.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T004714Z" creationid="Zhan" creationdate="20160427T003113Z">
        <seg>这就是为何数据科学家面临急需。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The *problem* of undirected graph connectivity is to identify connected components, whereas the *algorithm* of label propagation is a specific approach based on repeatedly circulating the smallest known node identifiers.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T072931Z" creationid="Zhan" creationdate="20160427T072931Z">
        <seg>无向图联通性 *问题* 是为找出联通子图，在这里这种标签传播 *算法* 是一种基于反复散布最小已知节点标记的特殊方法。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The Gödel Machine is a universal problem solver encoded as a completely self-referential program capable of rewriting any part of itself, provided it can prove that the rewrite is useful according to some utility function, encoded within itself.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T043159Z" creationid="Zhan" creationdate="20160427T043159Z">
        <seg>哥德尔机是一种通用问题求解器，其被编码为完全自引用程序，能够改写自身任一部分，通过一些实用函数，在其内进行自编码，可以证明重写用途。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The Gödel Machine was invented by Jürgen Schmidhuber in 2003.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T043913Z" creationid="Zhan" creationdate="20160427T043913Z">
        <seg>哥德尔机由 Jürgen Schmidhuber 在 2003 年发明。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The IT equivalent of Formula 1 race tuning won’t disappear: some apps will always require the utmost performance.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T012549Z" creationid="Zhan" creationdate="20160503T010130Z">
        <seg>IT 领域里如同 F1 方程式比赛一样的调优还不会消失︰ 总有一些应用需要极致的性能。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The MSST conference is going to have a number of talks that will explore the ins and outs of various workloads and how those workloads impact various storage systems.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T085017Z" creationid="Zhan" creationdate="20160428T085017Z">
        <seg>在 MSST 会议上将有大量的报告，将探讨各种工作负载和这些工作负载如何影响各种存储系统的来龙去脉。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The NVMW is a production of UCSD’s Non-Volatile Research Lab and the Center for Memory Recording Research.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T013800Z" creationid="Zhan" creationdate="20160322T103815Z">
        <seg>非易失存储器研讨会 NVMW 是由加州大学圣迭戈分校 UCSD 的非易失研究实验室与存储记录研究中心主办的。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The StorageMojo take</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T015040Z" creationid="Zhan" creationdate="20160427T015040Z">
        <seg>StorageMojo 评论</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The StorageMojo take
The full paper is a must-read for anyone professionally concerned with integrating new NVM technologies into systems.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T020412Z" creationid="Zhan" creationdate="20160323T020412Z">
        <seg>StorageMojo 评述
这篇论文对那些将 NVM 技术向系统进行整合有专业性考虑的人士而言是必读之作。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The StorageMojo take
This is StorageMojo, not AIMojo.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T044614Z" creationid="Zhan" creationdate="20160427T044614Z">
        <seg>StorageMojo 体会
这里是 StorageMojo，不是 AIMojo。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The [XStream paper](http://infoscience.epfl.ch/record/188535/files/paper.pdf) continues this specialization a bit more to an edge-centric Gather-Scatter interface, which allows the authors even greater flexibility in system implementation by further restricting the programming API.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160505T155247Z" creationid="Zhan" creationdate="20160505T155247Z">
        <seg>[XStream 论文] (http://infoscience.epfl.ch/record/188535/files/paper.pdf) 继续这种专门方法，推进一步构成一种以边为中心的聚散接口，由此通过进一步限制编程 API 给予算法作者在系统实现上更大的灵活性。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The advanced remote monitoring and sophisticated but easy to use DR features from Nimble are another example.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T004138Z" creationid="Zhan" creationdate="20160503T004138Z">
        <seg>Nimble 公司的 DR 功能是另一个例子，其提供先进的远程监控能力，虽然复杂精巧但易于使用。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The answer is no, of course, and the same applies for CPU performance.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T020920Z" creationid="Zhan" creationdate="20160428T020920Z">
        <seg>答案是不，当然，这同样适用于 CPU 的性能。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The benchmark requires one to compute the breadth-first distances and labels for a class of random graphs, and report the elapsed time.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T074513Z" creationid="Zhan" creationdate="20160427T074513Z">
        <seg>这项基准测试需要在随机图上计算广度优先遍历的距离和标签，然后报告所用时间。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The class of graph algorithms modern systems typically express is quite limited, and as [we've seen before](https://github.com/frankmcsherry/blog/blob/master/posts/2015-01-15.md), many modern graph processors don't outperform a laptop on their intended computations.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T070652Z" creationid="Zhan" creationdate="20160427T070626Z">
        <seg>现代系统通常表达的这类图论算法实际上有相当局限性 [我们以前见过] (https://github.com/frankmcsherry/blog/blob/master/posts/2015-01-15.md)，在其专属计算任务上，许多现代图形处理器甚至还不比笔记本电脑更强。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The combination of ease of development, ease of deployment, a great interface, backing by google, and all open sourced will push more of the community towards publishing their research on TensorFlow.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T015635Z" creationid="Zhan" creationdate="20160504T015635Z">
        <seg>由 Google 所支持，将易于开发、易于部署、伟大的界面相结合，而且还是完全开源的软件，将进一步推动社区使用 TensorFlow 来开展研究。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The connectivity to the storage system must take into account both the workflow and how that workflow impacts the underlying design of the storage system.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T080742Z" creationid="Zhan" creationdate="20160428T080742Z">
        <seg>连接到存储系统时，必须考虑工作流，以及这个工作流会如何影响其下存储系统的设计。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The converged and hyper converged platforms roll storage management in with systems management.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T003908Z" creationid="Zhan" creationdate="20160503T003908Z">
        <seg>聚合和超融合的平台将存储管理和系统管理集中在了一起。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The driver.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T004741Z" creationid="Zhan" creationdate="20160503T004741Z">
        <seg>驱动力。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The event attracts researchers from all over the world to present their work and make academic and commercial connections.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T013807Z" creationid="Zhan" creationdate="20160322T104151Z">
        <seg>这个会议吸引了来自全世界的研究人员介绍他们的成果，建立起学术界与商业界之间的联系。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The goal is balanced systems, and the key to having a balanced system is understanding your workload from end to end.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T084919Z" creationid="Zhan" creationdate="20160428T084919Z">
        <seg>目标在于平衡的系统，而构成平衡系统的关键在于从端到端理解你的工作负载。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The greater the mutual information, the more valuable the data and, hence, the higher the level of protection, access, and so on.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T005652Z" creationid="Zhan" creationdate="20160427T005652Z">
        <seg>互信息越大，就意味着数据更有价值，因此，就需要越高的保护级别，访问控制，等等。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The hyperscale guys have the incentive and the resources to perform deep analysis on new technologies.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T021424Z" creationid="Zhan" creationdate="20160323T021424Z">
        <seg>那些高杆们具备动机与资源来深入分析新技术。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The implication of the former is that since at least one improvement cannot be proved by the searcher, the AI will remain less than optimal.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T045655Z" creationid="Zhan" creationdate="20160427T044242Z">
        <seg>前者的引申含义是，因为至少一个改进不能通过搜索者证明，人工智能将仍然弱于最优。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The issue with crap algorithms is when they become benchmark computations for research areas.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T074246Z" creationid="Zhan" creationdate="20160427T074246Z">
        <seg>在没用算法成为研究领域计算性能评估的基准时，这就成为了问题。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The key is using machine learning to determine data value.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T004105Z" creationid="Zhan" creationdate="20160427T004105Z">
        <seg>其关键在于使用机器学习来确定数据价值。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The key word there is “assumption,” and when the data did not reside in cache, some vendors’ performance was pretty bad.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T080501Z" creationid="Zhan" creationdate="20160428T080501Z">
        <seg>这里的关键词是"假设，"，如果数据不驻留于缓存，一些供应商的产品性能就很糟糕。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The limits of AI
As Gödel proved, any formal system that includes arithmetic, either allows for unprovable but true statements, or is flawed.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T045645Z" creationid="Zhan" creationdate="20160427T044107Z">
        <seg>人工智能的极限
正如哥德尔(Gödel)所证明的，任何形式系统，包括算术，或者包含无法证明的永真命题，或者不完备。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The losers are the systems that make customers pay for features they no longer need.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T012629Z" creationid="Zhan" creationdate="20160503T010440Z">
        <seg>失败的系统是让用户为他们不再需要的功能买单的那些。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The main theme at this year’s Mass Storage Systems and Technology Conference (MSST) will be the importance of workflow over bandwidth or IOPs.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T020551Z" creationid="Zhan" creationdate="20160428T020551Z">
        <seg>在今年的海量存储系统和技术会议 （MSST）主要主题中，工作流的重要性将盖过带宽或 IOPs。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The other issue – beyond the scope of the paper – is also scale-related: how large will the storage system need to be to justify the cost and overhead of cognition?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T022420Z" creationid="Zhan" creationdate="20160427T022420Z">
        <seg>另一个问题 — — 超出论文主题 — — 也与规模相关︰ 存储系统要多大才足以给出认知所需成本和开销的充分理由？</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The paper assumes, correctly, that the big win for new NVM technologies will be as an adjunct to DRAM, rather than as flash SSD replacements – despite the fact that the first Xpoint product will be an Optane SSD.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T015019Z" creationid="Zhan" creationdate="20160323T015019Z">
        <seg>论文提出，正确的做法是，将新型 NVM 技术附加于 DRAM，而非用作闪存或者替换固态盘 – 尽管首款 Xpoint 产品仍是 Optane 固态盘。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The paper was presented at the Non-Volatile Memory Workshop last week at UCSD.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T013754Z" creationid="Zhan" creationdate="20160322T090900Z">
        <seg>这篇论文上周发表于 UCSD 召开的非易失存储器研讨会。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The point is that vendors have long designed hardware based on workflow, but it does not mean that all of this was obvious to everyone ten years ago.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T080626Z" creationid="Zhan" creationdate="20160428T080611Z">
        <seg>事实上厂商很早就基于工作流设计硬件，但这并不意味着，所有这一切在十年前众所周知。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The programming model introduced by Pregel was "think like a vertex", meaning: write a small program that could be run repeatedly by each graph vertex.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160502T064535Z" creationid="Zhan" creationdate="20160502T064535Z">
        <seg>由 Pregel 提出的编程模型即 "如同一个顶点一样思考"，含义︰ 写一个可以在每个顶点上重复运行的小程序。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The programs are delightfully simple for the tasks they considered; what's not to like?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160502T070442Z" creationid="Zhan" creationdate="20160502T065228Z">
        <seg>能简洁完成任务让这类程序受人喜欢；那有什么方面不受喜欢？</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The question is whether faster storage systems always mean faster workload throughput.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T020915Z" creationid="Zhan" creationdate="20160428T020915Z">
        <seg>问题是，是否更快的存储系统总是意味着更快的工作负载吞吐量。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The research in graph processing systems has (to my reading) largely focused on these problems as their core evaluation metrics, and consequently worked primarily to improve their performance on these problems.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T071244Z" creationid="Zhan" creationdate="20160427T071244Z">
        <seg>在图处理系统方向上的研究仍 （就我的阅读而言） 主要集中在以这些问题作为其核心的评价指标，也因此主要是为了提高他们在这些问题上的表现。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The researchers use a learning algorithm known as the “Information Bottleneck” (IB)</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T005043Z" creationid="Zhan" creationdate="20160427T005043Z">
        <seg>研究人员使用了一项被称作“信息瓶颈 (Information Bottleneck, IB)”的学习算法</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The results were very surprising for the customer and showed the potential for a significant improvement in workflow.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T085727Z" creationid="Zhan" creationdate="20160428T085727Z">
        <seg>试验结果令人非常吃惊，显示出在工作流中存在为客户做出重大改进的潜力。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The rise of data aware storage from Qumulo and Data Gravity makes it much simpler for less skilled staff to identify storage issues.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T003821Z" creationid="Zhan" creationdate="20160503T003821Z">
        <seg>数据感知存储公司 Qumulo 和 Data Gravity 的崛起，使得即便是不太熟练的工作人员也能处理存储相关问题。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The same goes for the hacker community.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T030425Z" creationid="Zhan" creationdate="20160504T030425Z">
        <seg>黑客社区也是一样。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The searcher seeks to improve the entire Gödel machine in a provably – subject to Gödel’s limits of provability, of course – optimal way.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T043846Z" creationid="Zhan" creationdate="20160427T043801Z">
        <seg>搜索者旨在从整体上以可证明最优的方式改善哥德尔机 — — 针对哥德尔受到的可证明性限制。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The software-only, commodity-based vendors whose products partly compete with cloud, also get it: Scale Computing’s first word on their website is “Simple”.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T012449Z" creationid="Zhan" creationdate="20160503T004653Z">
        <seg>就只做软件，且基于常规架构的供应商而言，其产品与云构成部分竞争， 也有这样的认识︰ 扩展计算的第一个词是 "简单"。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The solver interacts with some environment and determines utility using a reward function embedded in the machine.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T045555Z" creationid="Zhan" creationdate="20160427T043451Z">
        <seg>求解器与一些环境进行交互，并使用机器内嵌的奖励函数来确定效用。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The take-away is that they occasionally need to break out of vertex-centric computation into a centralized computation model.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160505T153334Z" creationid="Zhan" creationdate="20160505T153334Z">
        <seg>要点在于他们偶尔需要跳出顶点中心计算模型而改为使用集中计算模型。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>The trade-off analysis has to become more nuanced than the IOPS/endurance/latency discussions we have today.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T021252Z" creationid="Zhan" creationdate="20160323T021252Z">
        <seg>这个如何协调的分析比起我们现在讨论的 IOPS/endurance/latency 这些更为细致。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Their numbers wills shrink as the complexity that makes them necessary declines.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T010818Z" creationid="Zhan" creationdate="20160503T010818Z">
        <seg>他们的数量将随着使他们成为必须的复杂性一起持续萎缩。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>There are already multiple companies (in stealth) who are building platforms to easily manage and deploy TensorFlow applications.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T031131Z" creationid="Zhan" creationdate="20160504T031131Z">
        <seg>已有多家公司 （悄悄地） 构建能够轻松地管理和部署 TensorFlow 应用程序的平台。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>There have been 2 AI winters, periods of extreme hype regarding artificial intelligence followed by disappointment and funding cuts.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T022919Z" creationid="Zhan" creationdate="20160504T022919Z">
        <seg>历史上曾有过两次人工智能的冬季，那是关于人工智能的极端炒作时期，失望和经费削减随之而来。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>There have been sporadic attempts over the decades to add intelligence to storage systems, and they’ve all come to grief because the cost of the intelligence was higher than the cost of additional storage.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T023003Z" creationid="Zhan" creationdate="20160427T023003Z">
        <seg>几十年来已有零星尝试将智能性添加到存储系统，然而由于其成本高过直接追加存储所以并不成功。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>There may be an upper limit to how far deep learning technology will go, but as far as we know, we are nowhere near the plateau.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T023512Z" creationid="Zhan" creationdate="20160504T023512Z">
        <seg>深度学习技术能走多远，也许有其上限，但就我们所知，我们还远未爬上高原。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>There were already many deep learning libraries before TensorFlow.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T015714Z" creationid="Zhan" creationdate="20160504T015714Z">
        <seg>在 TensorFlow 之前已经有不少深度学习程序库。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>There will be an explosion of machine learning projects coming out from the hacker community.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T030519Z" creationid="Zhan" creationdate="20160504T030519Z">
        <seg>在黑客社区里，正将迎来一场机器学习项目的爆炸。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>These algorithms are not representative of graph processing problems.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T071552Z" creationid="Zhan" creationdate="20160427T071552Z">
        <seg>这些算法不是图形处理问题的代表。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>These platforms will only act to accelerate ubiquitous machine intelligence.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T031145Z" creationid="Zhan" creationdate="20160504T031145Z">
        <seg>这些平台将会加速无处不在机器智能。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>These systems seem to be optimizing the implementation of known algorithms, and then describing their APIs as the pluggable bits of their systems.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160505T154138Z" creationid="Zhan" creationdate="20160505T154138Z">
        <seg>看起来这些系统是为一些已知算法提供优化实现，然后将其封装为 API 便于在系统中灵活组装。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>These three algorithms (and minor variations) are ubiquitous because they are easy.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T071759Z" creationid="Zhan" creationdate="20160427T071743Z">
        <seg>这些三种算法 （和一些小变体） 是无处不在因为他们很容易。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>They consist of two main parts:</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T043238Z" creationid="Zhan" creationdate="20160427T043238Z">
        <seg>它们由两个主要部分组成 ︰</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>This algorithm came to popularity when folks were forced to use Hadoop, because writing sophisticated algorithims in Hadoop is really painful.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T073341Z" creationid="Zhan" creationdate="20160427T073341Z">
        <seg>当人们被迫使用 Hadoop 之时，这种算法就被普及，因为在 Hadoop 上编写精致复杂算法真的很棘手。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>This algorithm, however, is pretty crap.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T073107Z" creationid="Zhan" creationdate="20160427T073107Z">
        <seg>而这种算法，是漂亮的垃圾。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>This is especially true if SSDs are mixed in with standard hard drives.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T075212Z" creationid="Zhan" creationdate="20160428T075212Z">
        <seg>尤其是在固态盘与标准磁盘混合使用时更是如此。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>This is not to say that we can go back to 3 MB/sec disk drives that spin at 3600 RPM, but I am saying that workload throughput should count more than being able to do 1M IOPS or stream data at 600 MB/sec.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T020904Z" creationid="Zhan" creationdate="20160428T020646Z">
        <seg>当然这也不是说我们就要回去用 3 MB/秒 及 3600 RPM 转速的磁盘驱动器，我是指比起具备 1M IOPS 或者 600MB/秒 流式数据访问能力而言，工作负载吞吐量更有必要关注。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>This is totally great if you want to do something like pagerank or breadth-first search; there is a bunch of boiler plate you don't have to rewrite each time.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160505T154623Z" creationid="Zhan" creationdate="20160505T154623Z">
        <seg>如果你想要做如 pagerank 或广度优先搜索这类事，这个方案很棒，不必每次重写一大摞程序组件。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>This naturally leads to a focus on I/O stack latency, which multiple vendors are attacking.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T011639Z" creationid="Zhan" creationdate="20160503T002300Z">
        <seg>这自然导致 I/O 堆栈延迟深受关注，也由此招致多个供应商的攻击 。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>This of course needs to be abstracted to the volume manager and RAID layout, so it won’t be sequential on a disk drive unless the RAID layout is RAID-1, but there are still potential gotchas such as remapped sectors and virtual allocations.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T082449Z" creationid="Zhan" creationdate="20160428T082449Z">
        <seg>这当然需要通过卷管理器和 RAID 布局抽象层，所以它不会在磁盘驱动器上依然保持连续，除非 RAID 布局是 RAID 1，即便如此仍然有潜在可能存在重新映射和虚拟分配。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>This problem has many solutions developed over the years with a variety of interesting trade-offs.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T073047Z" creationid="Zhan" creationdate="20160427T073047Z">
        <seg>多年来就这个问题已开发出很多解决方案，有着各种有趣的权衡取舍。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>This section is a bit of a rant.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160505T160109Z" creationid="Zhan" creationdate="20160505T160109Z">
        <seg>这一节是有点咆哮。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>To compensate, the file system needs to explicitly flush data from the CPU’s caches to enforce orderings, adding significant overhead and squandering the improved performance that NVMM can provide.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160323T020208Z" creationid="Zhan" creationdate="20160323T020208Z">
        <seg>相应的，文件系统就需要显式的将数据从 CPU 缓存中刷回以强制重组数据，造成显著开销、浪费 NVMM 本可提供的性能提升。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Today most storage enclosures use 12 Gbit/sec SAS for internal communications, so each lane processes ~1.2 GB/sec, given protocol overhead.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T074606Z" creationid="Zhan" creationdate="20160428T074606Z">
        <seg>今天大多数存储机柜使用 12 Gb/秒 SAS 内部通信，所以每个通道 ~1.2 GB/秒，此即协议开销。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Touted by Intel and Micron as the first new memory tier to be launched since the introduction of NAND flash memory in 1989, its launch could have a significant effect on the storage market and your purchasing decisions.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T014558Z" creationid="Zhan" creationdate="20160428T014558Z">
        <seg>英特尔和镁光声称这是自1989 年引入 NAND 快闪存储器以来推出的首个新存储器层次，其面市将可能显著影响存储市场和你的购买决定。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Trading expressivity for manageabality can be a false economy.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160502T065336Z" creationid="Zhan" creationdate="20160502T065336Z">
        <seg>用可管理性来换取表达性恐怕是个经济错误。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Tuning HDD-based arrays for performance took a lot of knobs and dials – and people who understood them.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T005239Z" creationid="Zhan" creationdate="20160503T005239Z">
        <seg>调节磁盘阵列的性能有着复杂的细节 – 还需要熟悉他们的人。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Understanding its limits with respect to the foundation of any digital civilization – storage – is critical to our cultural infrastructure.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T023437Z" creationid="Zhan" creationdate="20160427T023437Z">
        <seg>以任意数字文化为基础来理解其限制 — — 存储 — — 对我们文化的基础设施至关重要。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Understanding what is happening with a single host is difficult, but as storage systems scale out with file systems and object systems that support hundreds if not thousands of client devices and applications, it gets really complex.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T083612Z" creationid="Zhan" creationdate="20160428T083612Z">
        <seg>理解单个主机之中发生了什么已很困难，但当存储系统与文件系统以及对象系统向外扩展直至支持上百个，不敢说是数以千计的客户端设备和应用程序时，问题将会非常复杂。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Unfortunately, it caught on.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T073937Z" creationid="Zhan" creationdate="20160427T073937Z">
        <seg>不幸的是，问题上钩啰。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>We are already breaking milestones almost every day in artificial intelligence thanks to deep learning.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T023124Z" creationid="Zhan" creationdate="20160504T023124Z">
        <seg>感谢深度学习，我们几乎每一天都在人工智能方向上突破一个又一个里程碑。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>We are also seeing a trend play out in a variety of product categories.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T003623Z" creationid="Zhan" creationdate="20160503T003623Z">
        <seg>我们从从一大波产品类别中观察到这个趋势正在涌现。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>We are living in exciting times.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T020407Z" creationid="Zhan" creationdate="20160504T020402Z">
        <seg>我们生活在一个激动人心的时代。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>We can see this trend with the growing revenue of AWS, Microsoft Azure, and Google Compute Engine.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T031107Z" creationid="Zhan" creationdate="20160504T031107Z">
        <seg>我们可以看到这样一个趋势，AWS、 微软 Azure 和谷歌计算引擎的收入正不断增长。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>We once took on strace for all of the applications running on a system and then built a simulation of the combined set of traces and ran this against various storage systems.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T085602Z" creationid="Zhan" creationdate="20160428T085602Z">
        <seg>我们曾经用 strace 在系统上采集所有运行于其中的应用程序行为，然后合并这些跟踪，在各种存储系统之上运行仿真。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>We’re facing a data onslaught like we’ve never seen before.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T002453Z" creationid="Zhan" creationdate="20160427T002417Z">
        <seg>我们正面临一场我们从未见过的数据倾泻.</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>What Do You Do With This Information?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T084035Z" creationid="Zhan" creationdate="20160428T080946Z">
        <seg>考虑这些情况你当如何处理？</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>What is a Gödel machine?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T041745Z" creationid="Zhan" creationdate="20160427T041745Z">
        <seg>什么是哥德尔机？</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>What is different and amazing about this hype cycle is that the doors for building intelligence into everything is being opened up to everyone.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T031609Z" creationid="Zhan" creationdate="20160504T021228Z">
        <seg>这种循环激励与众不同和令人惊讶之处在于，其具备为各个方面整合智能性的能力，并将之提供给大众。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>What's missing and what needs to get done next?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T073712Z" creationid="Zhan" creationdate="20160427T073712Z">
        <seg>还缺少什么，以及下一步还需要做什么？</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Wheat vs chaff</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T003740Z" creationid="Zhan" creationdate="20160427T003731Z">
        <seg>小麦 对 谷壳</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Where devices are placed in storage systems is becoming increasingly important, as back ends of storage controllers are not always homogeneous, and high-bandwidth activities such as rebuilding logical unit numbers (LUNs) after failure are bandwidth-hungry activities.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T075558Z" creationid="Zhan" creationdate="20160428T075558Z">
        <seg>由于存储控制器的后端设备并不总是同构，设备在存储系统中放置于何处显得越来越重要，而且还要考虑带宽密集型活动，比如出现故障后重建逻辑单元号 (Lun)。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>While the applications of machine intelligence are many, they aren’t infinite.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T094911Z" creationid="Zhan" creationdate="20160427T023238Z">
        <seg>机器智能的应用虽然很丰富，却并非无限。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Why now?</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T004703Z" creationid="Zhan" creationdate="20160503T004703Z">
        <seg>为何是现在？</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Why storage is getting simpler
by ROBIN HARRIS on MONDAY, 2 MAY, 2016</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T001942Z" creationid="Zhan" creationdate="20160503T001942Z">
        <seg>为什么存储越来越简单
罗宾 · 哈里斯 在星期一 2016 年 5 月 2 日</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Why TensorFlow will change the Game for AI ­ somatic blog
http://www.somatic.io/blog/why­tensorflow­will­change­the­game­for­ai
By jason 2016/5/4</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T012119Z" creationid="Zhan" creationdate="20160504T012119Z">
        <seg>为什么 TensorFlow 将改变 AI 的游戏 - 体细胞博客
http://www.somatic.io/blog/why­tensorflow­will­change­the­game­for­ai
作者 jason 于 2016/5/4</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Winners will successfully blend ease of use with performance and availability – at a competitive price.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T010632Z" creationid="Zhan" creationdate="20160503T010632Z">
        <seg>优胜者将在具有竞争力的价格上成功地融合易用性与性能和可用性。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>With a huge number of applications all hitting the storage system at once, most believe that I/O at the device level looks to be random because of the way blocks are allocated by file systems at the device.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T084001Z" creationid="Zhan" creationdate="20160428T084001Z">
        <seg>若数量庞大的应用程序同时集中访问存储系统，考虑文件系统从设备中分配块的方式，几乎可以确信从设备层面看起来 I/O 就是随机的。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>With all these new projects and research coming out, more people will be tinkering and building artificial intelligence applications.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T030759Z" creationid="Zhan" creationdate="20160504T030759Z">
        <seg>随着这些新项目与研究持续涌现，将有越来越多的人来尝试开发人工智能应用。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>With disk drives today operating at as much as 305 MB/sec and with SSDs operating at over 1200 MB/sec, SAS performance is now being replaced with NVMe because SAS is not up to the challenge.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160428T074937Z" creationid="Zhan" creationdate="20160428T074937Z">
        <seg>现在的磁盘驱动器工作速度高达 305 MB/秒，而固态盘则超过 1200 MB/秒，由于 SAS 性能难以应对这种挑战，因此 SAS 正在被 NVMe 所取代。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>With relatively small data sets, the team found that</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T014830Z" creationid="Zhan" creationdate="20160427T014830Z">
        <seg>在相对较小的数据集上，研究小组发现，</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>With the increase in people building off of TensorFlow, there will need to be a platform for deploying these intelligent programs.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T030849Z" creationid="Zhan" creationdate="20160504T030849Z">
        <seg>随着越来越多的人们开始用上 TensorFlow，需要有个平台来部署这些应用程序。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>With the release of TensorFlow, expect to see an increase in machine learning research.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T015328Z" creationid="Zhan" creationdate="20160504T015328Z">
        <seg>随着 TensorFlow 的发布，有望进一步推动机器学习方向上的研究。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>With the release of TensorFlow, innovation in artificial intelligence will dramatically increase.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T020459Z" creationid="Zhan" creationdate="20160504T020459Z">
        <seg>随着 TensorFlow 的发布，人工智能上的革新将飞速发展。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Yes, TensorFlow already makes it easy to deploy on your own hardware, but that is still not easy enough.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T030949Z" creationid="Zhan" creationdate="20160504T030949Z">
        <seg>没错，TensorFlow 已经使在自己的机器上部署变得容易，然而这还不够。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>Yes.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160503T010703Z" creationid="Zhan" creationdate="20160503T010703Z">
        <seg>没错。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>You do not need a PhD in math or computer science to be able to participate in this AI revolution.</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T022238Z" creationid="Zhan" creationdate="20160504T022238Z">
        <seg>而这，并不需要你拥有一个数学或者计算机科学博士学位，来参与这个人工智能革命。</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>[Original Post](http://storagemojo.com/2016/01/13/godel-machines-deep-learning-and-the-limits-of-ai/)</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T093429Z" creationid="Zhan" creationdate="20160427T093429Z">
        <seg>[原文](http://storagemojo.com/2016/01/13/godel-machines-deep-learning-and-the-limits-of-ai/)</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>[Original Post](http://storagemojo.com/2016/03/21/integrating-3d-xpoint-with-dram/)</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T093456Z" creationid="Zhan" creationdate="20160427T093456Z">
        <seg>[原文](http://storagemojo.com/2016/03/21/integrating-3d-xpoint-with-dram/)</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>[Original Post](http://storagemojo.com/2016/04/15/smart-storage-for-big-data/)</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T093357Z" creationid="Zhan" creationdate="20160427T093357Z">
        <seg>[原文](http://storagemojo.com/2016/04/15/smart-storage-for-big-data/)</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>[Original Post](https://github.com/frankmcsherry/blog/blob/master/posts/2015-12-24.md)</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160427T093414Z" creationid="Zhan" creationdate="20160427T093414Z">
        <seg>[原文](https://github.com/frankmcsherry/blog/blob/master/posts/2015-12-24.md)</seg>
      </tuv>
    </tu>
    <tu>
      <tuv lang="EN-US">
        <seg>“Machine learning is a core, transformative way by which we’re rethinking everything we’re doing.” — Google CEO, Sundar Pichai</seg>
      </tuv>
      <tuv lang="ZH-CN" changeid="Zhan" changedate="20160504T023758Z" creationid="Zhan" creationdate="20160504T023758Z">
        <seg>"机器学习是核心，是一种全新的方式，我们籍此重新思考着我们正在做的一切"— — 谷歌首席执行官，Sundar Pichai</seg>
      </tuv>
    </tu>
<!-- Alternative translations -->
  </body>
</tmx>
