发布于 2016 年 3 月 17 日
由亨利 · 纽曼
http://www.enterprisestorageforum.com/storage-hardware/why-workloads-matter-more-than-iops-or-streaming.html

随着磁盘驱动器和固态硬盘 (SSD) 越来越快，我认为现在是时候停下脚步审视一下什么才是真正重要的方面，换句话说，能完成多少工作，而非设备如何快。

在今年的海量存储系统和技术会议 （MSST）主要主题中，工作流的重要性将盖过带宽或 IOPs。当然这也不是说我们就要回去用 3 MB/秒 及 3600 RPM 转速的磁盘驱动器，我是指比起具备 1M IOPS 或者 600MB/秒 流式数据访问能力而言，工作负载吞吐量更有必要关注。

问题是，是否更快的存储系统总是意味着更快的工作负载吞吐量。答案是不，当然，这同样适用于 CPU 的性能。

所以是什么在影响存储系统的工作负载吞吐量？让我们从设备一侧开始，工作我们沿着堆栈向上进行分析。

设备的连接

随着设备越来越快、通道性能必须跟上。今天大多数存储机柜使用 12 Gb/秒 SAS 内部通信，所以每个通道 ~1.2 GB/秒，此即协议开销。现在的磁盘驱动器工作速度高达 305 MB/秒，而固态盘则超过 1200 MB/秒，由于 SAS 性能难以应对这种挑战，因此 SAS 正在被 NVMe 所取代。甚至对于磁盘驱动器而言，存储控制器上的 SAS 布局中，四个磁盘驱动器就足以让一个 SAS 通道饱和。

更快的存储需要重新设计的后端存储系统以确保提供足够的带宽，使每个存储设备可以全速运转。尤其是在固态盘与标准磁盘混合使用时更是如此。由于存储控制器的后端设备并不总是同构，设备在存储系统中放置于何处显得越来越重要，而且还要考虑带宽密集型活动，比如出现故障后重建逻辑单元号 (Lun)。

存储系统连接
现在用于连接存储系统的选项有 SAS、Infiniband、光纤通道和 NVMe。所有这些连接选项都要受到 PCIe 带宽限制，虽然这在未来会有改变，问题仍将相同︰ 主机服务器和存储系统之间需要多少带宽。

十年前，RAID 供应商有过相同的讨论，关于前端带宽 （服务器到缓存） 与后端带宽 （缓存到磁盘）。大多数的控制器在设计上给前端带宽很大的余量，这是基于大部分数据访问将集中在缓存中的假设。这里的关键词是"假设，"，如果数据不驻留于缓存，一些供应商的产品性能就很糟糕。

事实上厂商很早就基于工作流设计硬件，但这并不意味着，所有这一切在十年前众所周知。连接到存储系统时，必须考虑工作流，以及这个工作流会如何影响其下存储系统的设计。

主机端

现在我们来到这个问题中困难的部分。文件系统、卷管理器以及现在还有对象存储系统，其间应如何分配数据，又怎样在存储系统中摆放？例如，如果你有一个标准的 POSIX 文件系统，文件系统的空间分配策略是先入先出 (FIFO)。如果在一个案例中你有一个应用程序按照 1 MB 块大小顺序写 500 GB 1 MB 数据，而且如果你有足够的可用空间，该文件将在文件系统中被分配连续块地址。这当然需要通过卷管理器和 RAID 布局抽象层，所以它不会在磁盘驱动器上依然保持连续，除非 RAID 布局是 RAID 1，即便如此仍然有潜在可能存在重新映射和虚拟分配。

如果两个应用程序分别写两个不同的 500 GB 文件，那么就几乎可以肯定不会在磁盘上按顺序分配，考虑到文件系统是按照其分配策略分配数据，有可能预先分配空间，不过肯定没有 500 GB。因为对于大多数应用程序和文件系统而言，没有预分配命令，文件大小不可预知，多个文件同时打开写入数据将造成所分配空间相互交错。

所以只知道你的应用程序做了什么还不够; 你需要试着去了解与你的应用程序相应的存储系统做了什么，甚至还需要知道与此同时在系统上还运行着别的什么，这项任务更为复杂。理解单个主机之中发生了什么已很困难，但当存储系统与文件系统以及对象系统向外扩展直至支持上百个，不敢说是数以千计的客户端设备和应用程序时，问题将会非常复杂。若数量庞大的应用程序同时集中访问存储系统，考虑文件系统从设备中分配块的方式，几乎可以确信从设备层面看起来 I/O 就是随机的。

考虑这些情况你当如何处理？

在数据路径上任何一处都是一个潜在的瓶颈 — — 从文件系统中应用的数量 （我们别忘记操作系统 ！） 到 PCIe 总线到通往设备的通道。所有这一切加起来构成难以想象的复杂性，足以让人们用整个职业生涯来分析。

随着系统变得更大和命名空间变得更宽阔，这个问题将变得更糟。不过现在返回出发点：真正重要的还是你能作多少事，而非存储如何快，更何况快速存储并不总是意味着能做更多事。当然不仅对于存储如此，计算方面也一样，速度更快的 CPU 和更多内核不总是会转化为完成更多的工作。

目标在于平衡的系统，而构成平衡系统的关键在于从端到端理解你的工作负载。在 MSST 会议上将有大量的报告，将探讨各种工作负载和这些工作负载如何影响各种存储系统的来龙去脉。用 strace 来了解应用程序执行着哪些系统调用只不过是故事的一部分，因为这不能让人理解在存储层面上发生着什么。我们曾经用 strace 在系统上采集所有运行于其中的应用程序行为，然后合并这些跟踪，在各种存储系统之上运行仿真。试验结果令人非常吃惊，显示出在工作流中存在为客户做出重大改进的潜力。

如果你想要更好地理解最新的研究工作和那些正被用来认识工作流及其如何影响系统性能和系统体系结构的技术，我建议你收拾行囊去圣塔克拉拉参加 MSST。

照片由 Shutterstock 提供。


